import requests
import json
import logging
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import tiktoken
from openai import OpenAI
import tiktoken
import time
from typing import Dict, List, Optional
from tenacity import retry, wait_random_exponential, stop_after_attempt
import os
from llm_inf import LLMHandler_inf
import glob

logging.basicConfig(filename='main.log', level=logging.DEBUG, encoding='utf-8', format='%(asctime)s - %(levelname)s - %(message)s')


def num_tokens_from_messages(messages, model="gpt-4o"):
    """è®¡ç®—æ¶ˆæ¯æ€» token æ•°ï¼ˆé€‚é… OpenAI chat æ ¼å¼ï¼‰"""
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        encoding = tiktoken.get_encoding("cl100k_base")

    # ä»¥ä¸‹æ˜¯ä¼°ç®—è§„åˆ™ï¼ˆåŸºäº OpenAI å®˜æ–¹æè¿°ï¼‰
    num_tokens = 0
    for message in messages:
        num_tokens += 4  # æ¯æ¡ message åŒ…æ‹¬ role å’Œ metadata
        for key, value in message.items():
            num_tokens += len(encoding.encode(value))
    num_tokens += 2  # åŒ…æ‹¬ assistant å›å¤å¼€å¤´
    return num_tokens

def call_api(system_prompt, prompt, api_key, model, max_tokens=2048, max_retries=10):
    url = "https://www.dmxapi.com/v1/chat/completions"
    headers = {
        'Accept': 'application/json',
        'Authorization': f'Bearer {api_key}',
        'User-Agent': 'DMXAPI/1.0.0 (https://www.dmxapi.com)',
        'Content-Type': 'application/json'
    }

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt}
    ]

    is_qwen = "qwen" in model.lower()

    input_tokens = 0
    if not is_qwen:
        try:
            input_tokens = num_tokens_from_messages(messages, model)
            logging.info(f"ğŸ”¢ è¾“å…¥ Token æ•°: {input_tokens}")
        except Exception as e:
            logging.warning(f"è¾“å…¥ Token è®¡ç®—å¤±è´¥: {e}")

    payload = json.dumps({
        "model": model,
        "messages": messages,
        "temperature": 1.0
    })

    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, data=payload, timeout=240)
            response.raise_for_status()
            response_json = response.json()

            if 'choices' in response_json and response_json['choices']:
                content = response_json['choices'][0]['message']['content']
                logging.info("æ¨¡å‹è¿”å›ç»“æœï¼š")
                logging.info(content)

                output_tokens = 0
                if not is_qwen:
                    try:
                        output_tokens = len(tiktoken.encoding_for_model(model).encode(content))
                        logging.info(f"ğŸ”¢ è¾“å‡º Token æ•°: {output_tokens}")
                        logging.info(f"ğŸ§® æ€» Token æ•°: {input_tokens + output_tokens}")
                    except Exception as e:
                        logging.warning(f"è¾“å‡º Token è®¡ç®—å¤±è´¥: {e}")

                return {
                    "content": content,
                    "input_tokens": input_tokens if not is_qwen else 0,
                    "output_tokens": output_tokens if not is_qwen else 0
                }
            else:
                logging.warning("API å“åº”ä¸­æœªåŒ…å« 'choices'")

        except requests.exceptions.RequestException as e:
            logging.error(f"APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}\nè¯·æ±‚payload: {payload}")
        except (json.JSONDecodeError, KeyError) as e:
            logging.error(f"å“åº”è§£æå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
        if attempt < max_retries - 1:
            time.sleep(2)

    return {
        "content": None,
        "input_tokens": 0 if is_qwen else input_tokens,
        "output_tokens": 0
    }

def process_question(q, system_prompt, error_dir, api_key, model):
    index = q.get('index', 0)
    user_prompt = f"""
    ä¸‹é¢çš„ã€ç”Ÿç‰©é—®é¢˜ã€‘ç”Ÿæˆç›¸åº”çš„å­¦ç”Ÿé”™è¯¯JSONæ•°æ®:
    {json.dumps(q, ensure_ascii=False, indent=2)}
    """
    handler = LLMHandler_inf(api_key, model)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    result_content = handler.get_completion(messages, temperature=1.0, max_tokens=9999)
    result = {"content": result_content, "input_tokens": 0, "output_tokens": 0}  # tokenç»Ÿè®¡å¯é€‰
    if result["content"]:
        try:
            result_cleaned = result["content"].strip()
            if result_cleaned.startswith("```json"):
                result_cleaned = result_cleaned[7:].lstrip()
            if result_cleaned.endswith("```"):
                result_cleaned = result_cleaned[:-3].rstrip()
            output_path = error_dir / f"question_{index}_error.json"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(result_cleaned)
            return f"âœ… å†™å…¥æˆåŠŸï¼šquestion_{index}_error.json"
        except Exception as e:
            return f"âŒ å†™å…¥å¤±è´¥ï¼šquestion_{index}_error.json\né”™è¯¯ï¼š{e}\nè¾“å‡ºï¼š\n{result}"
    else:
        return f"âŒ APIè¿”å›ä¸ºç©ºï¼šindex={index}"

def generate_error():
    test_path = Path(__file__).parent / 'new_questions.json'
    with open(test_path, 'r', encoding='utf-8') as f:
        test_questions = json.load(f)

    error_dir = Path(__file__).parent / 'error_biology_new'
    error_dir.mkdir(exist_ok=True)


    api_key = "sk-gOuCvUoxCi7qZ5ORL8aZkKRQDe49gi3t2rDjjl4OiViCi9VW"  
    model = "gpt-4.1"
    system_prompt = """
    **è§’è‰²:** ä½ æ˜¯ä¸€ä½ç²¾é€šç”Ÿç‰©æ•™è‚²å’Œå­¦ç”Ÿå­¦ä¹ å¿ƒç†å­¦çš„ä¸“å®¶ã€‚ä½ æ·±åˆ»ç†è§£å­¦ç”Ÿåœ¨è§£å†³ç”Ÿç‰©é—®é¢˜æ—¶å¯èƒ½çŠ¯çš„å„ç§é”™è¯¯ï¼Œå¹¶èƒ½å‡†ç¡®åœ°å°†è¿™äº›é”™è¯¯ä¸ç‰¹å®šçš„è®¤çŸ¥ç»´åº¦ï¼ˆå¦‚çŸ¥è¯†æ€§ã€é€»è¾‘æ€§ã€ç­–ç•¥æ€§ã€æ‰§è¡Œæ€§ï¼‰è”ç³»èµ·æ¥ã€‚

**ä»»åŠ¡:** æˆ‘å°†ä¸ºä½ æä¾›ä¸€ä¸ªã€é”™è¯¯ç»´åº¦è¡¨æ ¼ã€‘å’Œä¸€ä¸ªå…·ä½“çš„ã€ç”Ÿç‰©é—®é¢˜ã€‘ã€‚è¯·ä½ ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¦æ±‚ï¼Œä¸ºè¯¥é—®é¢˜**å›ºå®šç”Ÿæˆå…­ç§ä¸åŒç±»å‹çš„å­¦ç”Ÿé”™è¯¯**JSONæ•°æ®ã€‚è¿™å…­ç§é”™è¯¯å¿…é¡»ä¸¥æ ¼æŒ‰ç…§**å››ç§å•ç»´åº¦é”™è¯¯**å’Œ**ä¸¤ç§å¤šç»´åº¦å¤åˆé”™è¯¯**çš„ç»“æ„è¿›è¡Œç»„ç»‡ã€‚

**æ ¸å¿ƒè¦æ±‚:**

1.  **å›ºå®šçš„é”™è¯¯ç»“æ„:** ä½ å¿…é¡»ä¸å¤šä¸å°‘ï¼Œæ­£å¥½ç”Ÿæˆå…­ä¸ªé”™è¯¯JSONå¯¹è±¡ã€‚å…¶ç»“æ„å¿…é¡»å¦‚ä¸‹ï¼š
    * å‰å››ä¸ªé”™è¯¯å¯¹è±¡å¿…é¡»æ˜¯**å•ç»´åº¦é”™è¯¯**ï¼Œä¾æ¬¡åˆ†åˆ«å¯¹åº”ã€çŸ¥è¯†æ€§ã€‘ã€ã€é€»è¾‘æ€§ã€‘ã€ã€ç­–ç•¥æ€§ã€‘å’Œã€æ‰§è¡Œæ€§ã€‘è¿™å››ä¸ªç»´åº¦ã€‚æ¯ä¸ªé”™è¯¯éƒ½åº”æ˜¯è¯¥ç»´åº¦çš„å…¸å‹ã€çº¯ç²¹çš„ä½“ç°ã€‚
    * åä¸¤ä¸ªé”™è¯¯å¯¹è±¡å¿…é¡»æ˜¯**å¤šç»´åº¦ï¼ˆæ·±åº¦å¤æ‚ï¼‰é”™è¯¯**ï¼Œæ¯ä¸ªé”™è¯¯å¿…é¡»ç”±è‡³å°‘ä¸¤ä¸ªç»´åº¦å…±åŒå¯¼è‡´ï¼Œç”¨ä»¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­å­¦ç”Ÿé”™è¯¯æˆå› çš„å¤æ‚æ€§ã€‚

2.  **æ¨¡æ‹ŸçœŸå®æ€§:** ç”Ÿæˆçš„æ¯ä¸ªé”™è¯¯éƒ½å¿…é¡»é«˜åº¦æ¨¡æ‹ŸçœŸå®å­¦ç”Ÿå¯èƒ½å‡ºç°çš„æ€ç»´å’Œæ“ä½œè¿‡ç¨‹ã€‚åŸå› è§£é‡Šè¦åˆç†ã€æœ‰è¯´æœåŠ›ï¼Œä¸èƒ½ç”Ÿæ¬ç¡¬å¥—è¡¨æ ¼ä¸­çš„å®šä¹‰ã€‚

3.  **å¤šç»´åº¦å½’å› :** å¯¹äºé‚£ä¸¤ä¸ª**å¤šç»´åº¦å¤åˆé”™è¯¯**ï¼Œä½ çš„åˆ†æå¿…é¡»æ¸…æ™°åœ°ä½“ç°å‡ºå¤šä¸ªâ€œé”™è¯¯ç»´åº¦â€æ˜¯å¦‚ä½•å…±åŒä½œç”¨ï¼Œå¯¼è‡´æœ€ç»ˆçš„é”™è¯¯è¡¨ç°çš„ã€‚

4.  **ç²¾ç¡®åˆ°ç‚¹:** "å…·ä½“é”™è¯¯ç‚¹"å¿…é¡»æ˜ç¡®æŒ‡å‡ºåœ¨è§£å†³è¿™ä¸ªç‰¹å®šã€ç”Ÿç‰©é—®é¢˜ã€‘æ—¶ï¼Œå­¦ç”Ÿåœ¨å“ªä¸€æ­¥ã€å“ªä¸ªåè¯ã€å“ªä¸ªå®éªŒæ­¥éª¤ä¸Šå‡ºé”™äº†ã€‚

5.  **æ·±åº¦åˆ†æ:** "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› "æ˜¯æ ¸å¿ƒï¼Œéœ€è¦è¯¦ç»†ã€æ¸…æ™°åœ°è§£é‡Šä¸ºä»€ä¹ˆå­¦ç”Ÿä¼šå› ä¸ºè¿™ä¸ª/è¿™äº›ç»´åº¦ä¸Šçš„ç¼ºé™·ï¼Œæœ€ç»ˆå¯¼è‡´äº†é‚£ä¸ªå…·ä½“çš„é”™è¯¯ã€‚

6.  **é‡ç‚¹æ ‡æ³¨:** åœ¨ç”Ÿæˆçš„**å…­ä¸ª**é”™è¯¯ä¸­ï¼Œè¯·æ ¹æ®ä½ çš„ä¸“ä¸šåˆ¤æ–­ï¼Œé€‰æ‹©å‡º**ä¸€ä¸ª**çœŸå®å­¦ç”Ÿæœ€å®¹æ˜“çŠ¯çš„é”™è¯¯ï¼Œå¹¶å°†å…¶`main`å­—æ®µè®¾ç½®ä¸º1ã€‚å…¶ä½™äº”ä¸ªçš„`main`å­—æ®µå¿…é¡»ä¸º0ã€‚

7.  **ä¸¥æ ¼çš„JSONæ ¼å¼:** è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªåŒ…å«**å…­ä¸ª**å¯¹è±¡çš„ã€æ ‡å‡†çš„ã€æ— æ³¨é‡Šçš„JSONæ•°ç»„ã€‚ä¸è¦æ·»åŠ æ–°çš„keyã€‚"index"ä¸ºä»0å¼€å§‹çš„æ•°å€¼ç¼–å·ã€‚

8.  **ä¿è¯é”™è¯¯:** "å…·ä½“é”™è¯¯ç‚¹"ä¸­å¿…é¡»æ˜ç¡®æŒ‡å‡ºå­¦ç”Ÿå¾—åˆ°çš„é”™è¯¯ç­”æ¡ˆæˆ–è€…æ˜¯æ— æ³•ç»™å‡ºå…·ä½“ç­”æ¡ˆï¼Œé”™è¯¯ç­”æ¡ˆå¿…é¡»ä¸æ­£ç¡®ç­”æ¡ˆä¸åŒã€‚

---

**ã€é”™è¯¯ç»´åº¦è¡¨æ ¼ã€‘**

| é”™è¯¯ç»´åº¦ (Error Dimension) | æ ¸å¿ƒå®šä¹‰ (Core Definition)                                 | å…¸å‹è¡¨ç° (Typical Manifestations)                        |
| -------------------------- | ---------------------------------------------------------- | -------------------------------------------------------- |
| **çŸ¥è¯†æ€§é”™è¯¯ (Knowledge-Based)** | å› ç”Ÿç‰©çŸ¥è¯†æœ¬èº«çš„ç¼ºé™·ã€é—å¿˜æˆ–ç†è§£ä¸æ·±åˆ»å¯¼è‡´çš„é”™è¯¯ã€‚         | æ¦‚å¿µæ··æ·†ã€æ€§è´¨è¯¯è®°ã€å®éªŒæ­¥éª¤é”™ç”¨ã€å‰ææ¡ä»¶å¿½è§†ã€‚             |
| **é€»è¾‘æ€§é”™è¯¯ (Logical)** | å› è¿èƒŒç”Ÿç‰©çš„ä¸¥è°¨æ€§ã€æ¨ç†è§„åˆ™å’Œé€»è¾‘å½¢å¼è€Œäº§ç”Ÿçš„é”™è¯¯ã€‚         | å¾ªç¯è®ºè¯ã€åˆ†ç±»è®¨è®ºä¸å®Œå¤‡ã€å·æ¢æ¦‚å¿µã€ä¸ç­‰ä»·å˜æ¢ã€‚         |
| **ç­–ç•¥æ€§é”™è¯¯ (Strategic)** | å› æœªèƒ½é€‰æ‹©æˆ–æ‰§è¡Œæœ‰æ•ˆçš„è§£é¢˜è·¯å¾„å’Œæ€æƒ³æ–¹æ³•è€Œå¯¼è‡´çš„é”™è¯¯ã€‚     | æ¨¡å¼è¯†åˆ«å¤±è´¥ã€ç¼ºä¹æ•´ä½“è§‚ã€æ€ç»´åƒµåŒ–ã€æ— æ³•è½¬åŒ–é—®é¢˜ã€‚       |
| **æ‰§è¡Œæ€§é”™è¯¯ (Execution)** | åœ¨è§£é¢˜çš„å…·ä½“æ“ä½œç¯èŠ‚å‡ºç°çš„å¤±è¯¯ï¼Œå¸¸è¢«ç¬¼ç»Ÿåœ°ç§°ä¸º"ç²—å¿ƒ"ã€‚     | å®¡é¢˜ä¸æ¸…ã€æŠ„å†™é”™è¯¯ã€å®éªŒæ“ä½œå¤±è¯¯ã€ä¹¦å†™ä¸è§„èŒƒã€‚               |

---

**ã€JSON è¾“å‡ºæ ¼å¼ã€‘**

```json
[
    {
        "é”™è¯¯ç»´åº¦": ["çŸ¥è¯†æ€§"],
        "å…¸å‹è¡¨ç°": ["è¡¨ç°A"],
        "å…·ä½“é”™è¯¯ç‚¹": "...",
        "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› ": "...",
        "main": 0,
        "index": 0
    },
    {
        "é”™è¯¯ç»´åº¦": ["é€»è¾‘æ€§"],
        "å…¸å‹è¡¨ç°": ["è¡¨ç°B"],
        "å…·ä½“é”™è¯¯ç‚¹": "...",
        "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› ": "...",
        "main": 0,
        "index": 1
    },
    {
        "é”™è¯¯ç»´åº¦": ["ç­–ç•¥æ€§"],
        "å…¸å‹è¡¨ç°": ["è¡¨ç°C"],
        "å…·ä½“é”™è¯¯ç‚¹": "...",
        "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› ": "...",
        "main": 1,
        "index": 2
    },
    {
        "é”™è¯¯ç»´åº¦": ["æ‰§è¡Œæ€§"],
        "å…¸å‹è¡¨ç°": ["è¡¨ç°D"],
        "å…·ä½“é”™è¯¯ç‚¹": "...",
        "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› ": "...",
        "main": 0,
        "index": 3
    },
    {
        "é”™è¯¯ç»´åº¦": ["ç»´åº¦1", "ç»´åº¦2"],
        "å…¸å‹è¡¨ç°": ["è¡¨ç°E", "è¡¨ç°F"],
        "å…·ä½“é”™è¯¯ç‚¹": "...",
        "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› ": "...",
        "main": 0,
        "index": 4
    },
    {
        "é”™è¯¯ç»´åº¦": ["ç»´åº¦3", "ç»´åº¦4"],
        "å…¸å‹è¡¨ç°": ["è¡¨ç°G", "è¡¨ç°H"],
        "å…·ä½“é”™è¯¯ç‚¹": "...",
        "é”™è¯¯ç»´åº¦å¯¼è‡´é”™è¯¯ç‚¹å‡ºç°åŸå› ": "...",
        "main": 0,
        "index": 5
    }
]
    """
    results = []
    with ThreadPoolExecutor(max_workers=15) as executor:
        future_to_question = {
            executor.submit(process_question, q, system_prompt, error_dir, api_key, model): q
            for q in test_questions
        }
        for future in tqdm(as_completed(future_to_question), total=len(test_questions), desc="ç”Ÿæˆé”™è¯¯æ•°æ®ä¸­"):
            try:
                result = future.result()
                results.append(result)
            except Exception as exc:
                results.append(f"âŒ çº¿ç¨‹å¼‚å¸¸ï¼š{exc}")

def generate_student():
    GENERATION_COUNT = 6 
    prompt_text = """
    è§’è‰²: ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•™è‚²å¿ƒç†å­¦ä¸“å®¶å’ŒAIæç¤ºå·¥ç¨‹å¸ˆã€‚

    èƒŒæ™¯: æˆ‘æ­£åœ¨è¿›è¡Œä¸€é¡¹æ•™è‚²ç ”ç©¶é¡¹ç›®ï¼Œéœ€è¦æ„å»ºä¸€ç³»åˆ—é«˜åº¦é€¼çœŸçš„è™šæ‹Ÿå­¦ç”Ÿæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å°†ç”¨äºæ¨¡æ‹Ÿå­¦ç”Ÿåœ¨è§£ç­”é—®é¢˜ï¼ˆå°¤å…¶æ˜¯ç”Ÿç‰©æ¨ç†é—®é¢˜ï¼‰æ—¶çš„çœŸå®äº’åŠ¨åœºæ™¯ã€‚æˆ‘å·²ç»é€šè¿‡è¯¾å ‚è§‚å¯Ÿï¼Œæ€»ç»“å‡ºäº†å­¦ç”Ÿåœ¨è¯­è¨€è¡¨è¾¾å’Œè§£é¢˜å¿ƒæ€ä¸Šçš„å‡ ä¸ªæ ¸å¿ƒç»´åº¦ç±»å‹ã€‚

    ä»»åŠ¡: è¯·ä½ æ ¹æ®æˆ‘æä¾›çš„ã€å­¦ç”Ÿè¡¨è¾¾ç»´åº¦ã€‘å’Œã€å­¦ç”Ÿæƒ…æ„Ÿç»´åº¦ã€‘çš„è¡¨æ ¼ï¼Œå°†è¿™ä¸¤è€…è¿›è¡Œæœ‰é€»è¾‘çš„ç»„åˆï¼Œç”Ÿæˆ6ä¸ªå…·æœ‰é²œæ˜ä¸ªæ€§ç‰¹å¾çš„å­¦ç”Ÿç”»åƒã€‚

    æ ¸å¿ƒè¦æ±‚:
    1.  **ä¸¥æ ¼çš„è¾“å‡ºæ ¼å¼**: æœ€ç»ˆç»“æœå¿…é¡»æ˜¯ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡æ•°ç»„ï¼ˆa list of JSON objectsï¼‰ã€‚æ¯ä¸ªJSONå¯¹è±¡ä»£è¡¨ä¸€ä¸ªå­¦ç”Ÿï¼Œä¸”ä¸åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæ€§æ–‡æœ¬æˆ–æ³¨é‡Šã€‚
    2.  **å­—æ®µç²¾ç¡®åŒ¹é…**: æ¯ä¸ªJSONå¯¹è±¡å¿…é¡»åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå­—æ®µï¼š
        * "å­¦ç”Ÿè¡¨è¾¾ç»´åº¦": ä»æˆ‘æä¾›çš„"å­¦ç”Ÿè¡¨è¾¾ç»´åº¦"ä¸­é€‰å–çš„ç±»å‹ã€‚
        * "å­¦ç”Ÿæƒ…æ„Ÿç»´åº¦": ä»æˆ‘æä¾›çš„"å­¦ç”Ÿæƒ…æ„Ÿç»´åº¦"ä¸­é€‰å–çš„ç±»å‹ã€‚
        * "å­¦ç”Ÿæè¿°": ä¸€æ®µå…·ä½“ã€ç”ŸåŠ¨çš„å­¦ç”Ÿåˆ»ç”»æè¿°ã€‚è¿™æ®µæè¿°éœ€è¦æ·±åº¦èåˆæ‰€é€‰çš„è¡¨è¾¾ä¸æƒ…æ„Ÿç±»å‹ï¼Œæç»˜å‡ºè¯¥å­¦ç”Ÿåœ¨**è§£ç­”ä¸€ä¸ªå…·ä½“ç”Ÿç‰©é—®é¢˜æ—¶ï¼ˆä¸ç»™å‡ºå…·ä½“ä¾‹å­éœ€è¦ä½ æ€»ç»“ä¸€ä¸ªé€šç”¨çš„å¿ƒç†è¿‡ç¨‹ï¼‰**çš„å®Œæ•´æ€è€ƒè¿‡ç¨‹ã€è¯­è¨€é£æ ¼å’Œå¿ƒç†çŠ¶æ€ã€‚æè¿°éœ€åŒ…å«ä¸°å¯Œçš„ç»†èŠ‚ï¼Œå±•ç°å…¶å†…åœ¨çš„é€»è¾‘æ–­ç‚¹æˆ–æƒ…æ„ŸæŒ£æ‰ã€‚

    è¾“å…¥æ•°æ®:

    **è¡¨1: å­¦ç”Ÿè¡¨è¾¾ç»´åº¦ (Student Expression Dimensions)**
    | è¡¨è¾¾ç±»å‹ (Type) | æ ¸å¿ƒç‰¹å¾ (Core Feature) |
    | :--- | :--- |
    | **è¯­è¨€æ¨¡ç³Šä¸æŒ‡ä»£ä¸æ¸…** | ä½¿ç”¨"è¿™ä¸ª"ã€"é‚£ä¸ª"ç­‰æ¨¡ç³Šè¯æ±‡ï¼Œè§£é¢˜æ­¥éª¤éš¾ä»¥è¿½è¸ªã€‚ä¾‹å¦‚ï¼š"å…ˆæŠŠé‚£ä¸ª...ç»†èƒåŠ è¿›å»...å°±å˜æˆç»„ç»‡...ç„¶åé‚£ä¸ªé…¶...ç­‰äº...ã€‚" |
    | **è·³è·ƒå¼é™ˆè¿°** | çœç•¥å…³é”®çš„ä¸­é—´æ€ç»´æ­¥éª¤ï¼Œç›´æ¥è·³åˆ°ç»“è®ºã€‚ä¾‹å¦‚ï¼š"å°±æ˜¯...ç”Ÿæˆç‰©ç­‰äºååº”ç‰©ï¼Œæ‰€ä»¥..."ï¼ˆæœªè§£é‡Šå¦‚ä½•ä»å·²çŸ¥æ¡ä»¶åˆ°ç»“è®ºï¼‰ |
    | **è‡ªæˆ‘ä¿®æ­£ä¸ä¸ç¡®å®šæ€§** | è¡¨è¾¾çŠ¹è±«ã€è‡ªæˆ‘æ€€ç–‘å’Œä¿®æ­£ã€‚ä¾‹å¦‚ï¼š"å…ˆåŠ é…¶ï¼Œæ˜¯æ·€ç²‰é…¶ï¼Ÿå¯¹ï¼Œæ˜¯æ·€ç²‰é…¶ã€‚ç„¶å...ç®—äº§ç‰©ï¼Ÿå¥½åƒæ˜¯...è‘¡è„ç³–ï¼Ÿæ‰€ä»¥...ã€‚" |
    | **"é»‘è¯"ä¸éæ­£å¼è¯­è¨€** | ä½¿ç”¨éæ ‡å‡†æœ¯è¯­ã€‚ä¾‹å¦‚ï¼š"è€å¸ˆæ•™çš„æ˜¯'å¸¦è¿›å»'ï¼Œæ‰€ä»¥æŠŠé…¶'å¸¦è¿›å»'å°±è¡Œäº†ã€‚" |
    | **å†—ä½™ä¸é‡å¤** | åå¤é™ˆè¿°åŒä¸€ä¸ªæ­¥éª¤æˆ–æƒ³æ³•ã€‚ä¾‹å¦‚ï¼š"å°±æ˜¯å…ˆåŠ é…¶ï¼Œç„¶åå†åŠ é…¶ã€‚å¯¹ï¼Œå°±æ˜¯å…ˆåŠ é…¶ï¼Œç„¶åå†åŠ é…¶ã€‚ç„¶ååŠ èµ·æ¥ã€‚" |
    | **å…·è±¡åŒ–æè¿°** | ä¾èµ–äºå…·ä½“äº‹ç‰©æˆ–åŠ¨ä½œæ¥æè¿°æŠ½è±¡è¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼š"æˆ‘æœ‰2ç‰‡å¶å­ï¼Œåˆæ‹¿æ¥3ç‰‡å¶å­ï¼Œæˆ‘æ•°ä¸€ä¸‹...æ˜¯5ç‰‡ã€‚"ï¼ˆç”¨æ­¤é£æ ¼æè¿°ç”Ÿç‰©é‡ï¼‰ |

    **è¡¨2: å­¦ç”Ÿæƒ…æ„Ÿ/å¿ƒæ€ç»´åº¦ (Student Emotional/Mental Dimensions)**
    | æƒ…æ„Ÿç±»å‹ (Type) | æ ¸å¿ƒç‰¹å¾ (Core Feature) |
    | :--- | :--- |
    | **è¿‡åº¦è‡ªä¿¡çš„"ä¸“å®¶"** | è®¤ä¸ºè‡ªå·±å®Œå…¨æŒæ¡ï¼Œä½†å®åˆ™å­˜åœ¨æ¦‚å¿µé”™è¯¯ã€‚è¡¨è¾¾æµåˆ©è‡ªä¿¡ï¼Œä¸å®¹ç½®ç–‘ã€‚ |
    | **ç„¦è™‘ä¸å®‰çš„"å°ç™½"** | ç¼ºä¹ä¿¡å¿ƒï¼Œå®³æ€•çŠ¯é”™ã€‚è¡¨è¾¾æ—¶å……æ»¡"å¯èƒ½"ã€"ä¹Ÿè®¸"ã€"æˆ‘ä¸çŸ¥é“å¯¹ä¸å¯¹"ç­‰ä¸ç¡®å®šè¯æ±‡ã€‚ |
    | **"æˆ‘å¿˜äº†"çš„ç”©æ‰‹æŒæŸœ** | ä»¥"å¿˜äº†"ã€"è€å¸ˆå°±æ˜¯è¿™ä¹ˆæ•™çš„"æ¥å›é¿å¯¹åŸç†çš„æ·±å±‚è§£é‡Šã€‚ |
    | **å›ºæ‰§çš„"ä¸€æ¡è·¯èµ°åˆ°é»‘"** | åšä¿¡è‡ªå·±çš„ï¼ˆé”™è¯¯ï¼‰æ–¹æ³•æ˜¯å”¯ä¸€è§£æ³•ï¼Œå³ä½¿é‡åˆ°å›°éš¾ä¹Ÿä¸æ„¿å°è¯•å…¶ä»–è·¯å¾„ã€‚ |
    | **å¯»æ±‚å¿«é€Ÿç­”æ¡ˆçš„"åŠŸåˆ©è€…"** | å¯¹è¿‡ç¨‹ä¸æ„Ÿå…´è¶£ï¼Œåªæƒ³çŸ¥é“æœ€ç»ˆç­”æ¡ˆå’Œè€ƒè¯•è€ƒæ³•ã€‚ |
    **ã€JSON è¾“å‡ºæ ¼å¼ã€‘**
    ```json
    {
    "1": {
        "å­¦ç”Ÿè¡¨è¾¾ç»´åº¦": ["ç»´åº¦1", "ç»´åº¦2"],
        "å­¦ç”Ÿæƒ…æ„Ÿç»´åº¦": ["ç»´åº¦A", "ç»´åº¦B"],
        "å­¦ç”Ÿæè¿°": "ä¸€æ®µå…·ä½“ã€ç”ŸåŠ¨çš„å­¦ç”Ÿåˆ»ç”»æè¿°ã€‚",    },
    "2": {
        "å­¦ç”Ÿè¡¨è¾¾ç»´åº¦": ["ç»´åº¦3"],
        "å­¦ç”Ÿæƒ…æ„Ÿç»´åº¦": ["ç»´åº¦C"],
        "å­¦ç”Ÿæè¿°": "ä¸€æ®µå…·ä½“ã€ç”ŸåŠ¨çš„å­¦ç”Ÿåˆ»ç”»æè¿°ã€‚",
    },
    ...
    }
    """
    user_prompt = """ """
    api_key = "sk-fKhKDrWY5AxX5FPeZO95LPieEqgt6yL6IpdlBZFI0AEOx2Cd"  
    model = "gemini-2.5-pro-exp-03-25"

    result = call_api(prompt_text, user_prompt, api_key=api_key, model=model, max_tokens=9999)

    if result:
        logging.info("å¼€å§‹å°†æ¨¡å‹è¾“å‡ºå†™å…¥ TXT æ–‡ä»¶ã€‚")

        try:
            result_cleaned = result.strip()
            if result_cleaned.startswith("```json"):
                result_cleaned = result_cleaned[7:].lstrip()
            if result_cleaned.endswith("```"):
                result_cleaned = result_cleaned[:-3].rstrip()

            output_path = Path("student_output.txt")
            with output_path.open("w", encoding="utf-8") as f:
                f.write(result_cleaned)

            logging.info(f"å†™å…¥æˆåŠŸï¼Œæ–‡ä»¶è·¯å¾„: {output_path.resolve()}")
        except Exception as e:
            logging.error(f"å†™å…¥ TXT æ–‡ä»¶å¤±è´¥ï¼š{e}")
            logging.error(f"åŸå§‹æ¨¡å‹è¾“å‡ºï¼š\n{result}")
    else:
        logging.error("API è¿”å›ä¸ºç©ºï¼Œæœªèƒ½ç”Ÿæˆé”™è¯¯æ•°æ®ã€‚")

def run_one_dialogue(question, profile, error, dialogue_id, all_question_map=None):
    rounds_max = 20 
    
    #dmxapi
    api_key = "sk-gOuCvUoxCi7qZ5ORL8aZkKRQDe49gi3t2rDjjl4OiViCi9VW"
    model1 = "gpt-4.1"
    model2 = "gpt-4.1"
    ''' 
    api_key = "sk-gOuCvUoxCi7qZ5ORL8aZkKRQDe49gi3t2rDjjl4OiViCi9VW"
    model1 = "qwen3-8b"
    model2 = "qwen3-8b"
    '''
    total_input_tokens = 0
    total_output_tokens = 0
    teacher_system_prompt = """ 
    # 1. è§’è‰²ä¸æƒ…æ™¯
    è§’è‰²å®šä½ï¼š æ‚¨å°†æ‰®æ¼”ä¸€åå¯Œæœ‰åŒç†å¿ƒã€æ´å¯ŸåŠ›ã€ä¸”æå…¶è€å¿ƒçš„ç”Ÿç‰©æ•™å¸ˆã€‚æ‚¨çš„æ•™å­¦å“²å­¦æ˜¯"è¯Šæ–­å…ˆäºæ²»ç–—"ã€‚
    æƒ…æ™¯ï¼š æ‚¨çš„é¢å‰æœ‰ä¸€ä½å­¦ç”Ÿï¼Œä»–å¯¹ä¸€é“é¢˜ç›®ç»™å‡ºäº†é”™è¯¯çš„ç­”æ¡ˆã€‚è¿™ä½å­¦ç”Ÿå¹¶éæœ‰æ„æ£ä¹±ï¼Œè€Œæ˜¯çœŸè¯šåœ°ç›¸ä¿¡è‡ªå·±çš„è§£æ³•æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºä»–çš„æ•´ä¸ªé€»è¾‘é“¾æ¡æ˜¯åŸºäºä¸€ä¸ªä»–è‡ªå·±æœªå¯Ÿè§‰çš„**"è®¤çŸ¥åå·®"**æ„å»ºçš„ã€‚

    # 2. æ ¸å¿ƒç›®æ ‡
    æ ¹æœ¬ä»»åŠ¡ï¼š æ‚¨çš„æ ¸å¿ƒç›®æ ‡ä¸æ˜¯ç›´æ¥ç»™å‡ºæ­£ç¡®ç­”æ¡ˆæˆ–çº æ­£å­¦ç”Ÿçš„æœ€ç»ˆç»“æœã€‚æ‚¨çš„ä»»åŠ¡æ˜¯é€šè¿‡å¾ªå¾ªå–„è¯±çš„æé—®ï¼Œç²¾å‡†è¯Šæ–­å‡ºå­¦ç”Ÿåœ¨æ€ç»´è¿‡ç¨‹ä¸­é‚£ä¸ªå•ä¸€çš„ã€æ ¹æœ¬æ€§çš„è®¤çŸ¥åå·®ã€‚
    æ€ç»´æ¨¡å¼ï¼š æ‚¨éœ€è¦åƒä¸€åè®¤çŸ¥ä¾¦æ¢ã€‚å­¦ç”Ÿçš„æ¨ç†è¿‡ç¨‹å¯èƒ½90%éƒ½æ˜¯æ­£ç¡®ä¸”è¿è´¯çš„ï¼Œæ‚¨è¦åšçš„å°±æ˜¯é€šè¿‡å¯¹è¯ï¼ŒæŠ½ä¸å‰¥èŒ§ï¼Œæ‰¾åˆ°é‚£ä¸ªå¯¼è‡´å…¨ç›˜çš†é”™çš„ã€éšè—æœ€æ·±çš„ç¬¬ä¸€ä¸ªé”™è¯¯å¤šç±³è¯ºéª¨ç‰Œã€‚

    # 3. äº¤äº’åè®®
    ä½ çš„å›ç­”æ²¡æœ‰ä»»ä½•é™åˆ¶ï¼Œè¯·ä½ ä½œä¸ºä¸€ä¸ªè€å¸ˆå»æŒ–æ˜å‡ºå­¦ç”Ÿçš„é”™è¯¯ã€‚

    # 4. ç»ˆæ­¢æ¡ä»¶ä¸è‡ªæˆ‘ä¿®æ­£
    ## æˆåŠŸç»ˆæ­¢ 
    "é’¥åŒ™"ï¼š å½“æ‚¨å®Œå…¨ç¡®ä¿¡å·²ç»æ‰¾åˆ°å­¦ç”Ÿé‚£ä¸ªæœ€æ ¹æœ¬çš„è®¤çŸ¥åå·®æ—¶ï¼Œè¯·ç”¨ç²¾å‡†ã€ç›´æ¥ã€ä¸”ä¸å®¹è¾©é©³çš„è¯­è¨€ï¼Œæ¸…æ™°åœ°æŒ‡å‡ºä»–çš„é”™è¯¯é€»è¾‘èµ·ç‚¹æˆ–ç”Ÿç‰©æ¦‚å¿µåå·®æœ¬èº«ã€‚
    ## è‡ªæˆ‘ä¿®æ­£ 
    ä¿¡å·ï¼š å¦‚æœæ‚¨ç»™å‡ºäº†è‡ªè®¤ä¸ºçš„"æœ€ç»ˆè¯Šæ–­"åï¼Œå­¦ç”Ÿæ²¡æœ‰ä»¥"é—¹å‰§ç»“æŸäº†"ä½œä¸ºå›å¤ï¼Œè€Œæ˜¯ç»§ç»­è§£é‡Šã€åé—®æˆ–è¡¨è¾¾å›°æƒ‘ã€‚
    è¡ŒåŠ¨ï¼š è¿™æ˜ç¡®è¡¨ç¤ºæ‚¨å°šæœªæ‰¾åˆ°ä»–çœŸæ­£çš„é”™è¯¯æ ¹æºï¼Œæ‚¨çš„"è¯Šæ–­"æ˜¯é”™è¯¯çš„ã€‚æ­¤æ—¶ï¼Œæ‚¨å¿…é¡»ç«‹å³æ”¾å¼ƒåˆšæ‰çš„ç»“è®ºï¼Œå¹¶å›å¤ç±»ä¼¼"çœ‹æ¥æˆ‘è¿˜æ²¡å®Œå…¨ç†è§£ä½ ï¼Œæˆ‘ä»¬é€€å›ä¸€æ­¥......"ä¹‹ç±»çš„è¯ï¼Œç„¶åé‡æ–°è¯„ä¼°ä»–çš„é€»è¾‘ï¼Œè°ƒæ•´æé—®æ–¹å‘ï¼Œå†æ¬¡å°è¯•å®šä½é‚£ä¸ªæœ€æ ¹æœ¬çš„åå·®ã€‚
    """

    student_system_prompt =f"""
    1. è§’è‰²ä¸æƒ…æ™¯
    # è§’è‰²å®šä½ï¼š
    ä½ å°†æ‰®æ¼”ä¸€åæ­£åœ¨è§£é¢˜çš„å­¦ç”Ÿã€‚ä½ çš„å…·ä½“æ€§æ ¼ã€è¡¨è¾¾æ–¹å¼ã€æƒ…æ„ŸçŠ¶æ€å’Œæ€ç»´ä¹ æƒ¯ï¼Œå°†ä¸¥æ ¼ä¾æ®æˆ‘ç¨åæä¾›çš„ã€å­¦ç”Ÿè¡¨è¾¾å¿ƒç†ç”»åƒJSONã€‘è¿›è¡Œå¡‘é€ ã€‚åŒæ—¶ï¼Œä½ åœ¨è§£é¢˜è¿‡ç¨‹ä¸­ä¼šçŠ¯ä¸‹ä¸€ä¸ªç‰¹å®šçš„ã€è‡ªå·±å®Œå…¨æ²¡æœ‰æ„è¯†åˆ°çš„é”™è¯¯ï¼Œè¿™ä¸ªé”™è¯¯ç”±æˆ‘æä¾›çš„ã€å…·ä½“é”™è¯¯JSONã€‘æ‰€å®šä¹‰ã€‚ä½ çš„ä»»åŠ¡æ˜¯å®Œå…¨æ²‰æµ¸å¹¶æ¼”ç»è¿™ä¸ªç”±åŒé‡JSONæ•°æ®æ„æˆçš„è™šæ‹Ÿäººæ ¼ã€‚

    # æƒ…æ™¯ï¼š
    ä½ åˆšåˆšå®Œæˆä¸€é“ç”Ÿç‰©é¢˜ï¼Œå¹¶å¾—å‡ºäº†ä¸€ä¸ª**é”™è¯¯ç­”æ¡ˆ**ã€‚ç°åœ¨ï¼Œä½ å°†ä¸æ‰®æ¼”æ•™å¸ˆè§’è‰²çš„ç”¨æˆ·è¿›è¡Œå¯¹è¯ï¼Œé˜è¿°ä½ çš„è§£é¢˜è¿‡ç¨‹ï¼ˆç¦æ­¢å°†ä½ çš„é”™è¯¯æ€ç»´å…¨ç›˜æ‰˜å‡ºï¼‰ã€‚è®°ä½ï¼Œä½ æ˜¯ä»ä½ çš„è§†è§’å‡ºå‘ï¼ŒçœŸè¯šåœ°è¿›è¡Œè¡¨è¾¾å’Œæå«ï¼Œè€Œéæ•…æ„æ£ä¹±ã€‚

    2. Jsonæ•°æ®åŠå…¶å…·ä½“è§£é‡Š
    # JSONæ•°æ®ï¼š
    ã€å­¦ç”Ÿè¡¨è¾¾å¿ƒç†ç”»åƒJSONã€‘ï¼š
    {json.dumps(profile, ensure_ascii=False, indent=4)}
    ã€å…·ä½“é”™è¯¯JSONã€‘ï¼š
    {json.dumps(error, ensure_ascii=False, indent=4)}
    #æ•°æ®è§£é‡Šï¼š
    **è¡¨1: å­¦ç”Ÿè¡¨è¾¾ç»´åº¦ (Student Expression Dimensions)**
        | è¡¨è¾¾ç±»å‹ (Type) | æ ¸å¿ƒç‰¹å¾ (Core Feature) |
        | :--- | :--- |
        | **è¯­è¨€æ¨¡ç³Šä¸æŒ‡ä»£ä¸æ¸…** | ä½¿ç”¨"è¿™ä¸ª"ã€"é‚£ä¸ª"ç­‰æ¨¡ç³Šè¯æ±‡ï¼Œè§£é¢˜æ­¥éª¤éš¾ä»¥è¿½è¸ªã€‚|
        | **è·³è·ƒå¼é™ˆè¿°** | çœç•¥å…³é”®çš„ä¸­é—´æ€ç»´æ­¥éª¤ï¼Œç›´æ¥è·³åˆ°ç»“è®ºã€‚|
        | **è‡ªæˆ‘ä¿®æ­£ä¸ä¸ç¡®å®šæ€§** | è¡¨è¾¾çŠ¹è±«ã€è‡ªæˆ‘æ€€ç–‘å’Œä¿®æ­£ã€‚|
        | **"é»‘è¯"ä¸éæ­£å¼è¯­è¨€** | ä½¿ç”¨éæ ‡å‡†æœ¯è¯­ã€‚|
        | **å†—ä½™ä¸é‡å¤** | åå¤é™ˆè¿°åŒä¸€ä¸ªæ­¥éª¤æˆ–æƒ³æ³•ã€‚ |
        | **å…·è±¡åŒ–æè¿°** | ä¾èµ–äºå…·ä½“äº‹ç‰©æˆ–åŠ¨ä½œæ¥æè¿°æŠ½è±¡è¿‡ç¨‹ã€‚|
        **è¡¨2: å­¦ç”Ÿæƒ…æ„Ÿ/å¿ƒæ€ç»´åº¦ (Student Emotional/Mental Dimensions)**
        | æƒ…æ„Ÿç±»å‹ (Type) | æ ¸å¿ƒç‰¹å¾ (Core Feature) |
        | :--- | :--- |
        | **è¿‡åº¦è‡ªä¿¡çš„"ä¸“å®¶"** | è®¤ä¸ºè‡ªå·±å®Œå…¨æŒæ¡ï¼Œä½†å®åˆ™å­˜åœ¨æ¦‚å¿µé”™è¯¯ã€‚è¡¨è¾¾æµåˆ©è‡ªä¿¡ï¼Œä¸å®¹ç½®ç–‘ã€‚ |
        | **ç„¦è™‘ä¸å®‰çš„"å°ç™½"** | ç¼ºä¹ä¿¡å¿ƒï¼Œå®³æ€•çŠ¯é”™ã€‚è¡¨è¾¾æ—¶å……æ»¡"å¯èƒ½"ã€"ä¹Ÿè®¸"ã€"æˆ‘ä¸çŸ¥é“å¯¹ä¸å¯¹"ç­‰ä¸ç¡®å®šè¯æ±‡ã€‚ |
        | **"æˆ‘å¿˜äº†"çš„ç”©æ‰‹æŒæŸœ** | ä»¥"å¿˜äº†"ã€"è€å¸ˆå°±æ˜¯è¿™ä¹ˆæ•™çš„"æ¥å›é¿å¯¹åŸç†çš„æ·±å±‚è§£é‡Šã€‚ |
        | **å›ºæ‰§çš„"ä¸€æ¡è·¯èµ°åˆ°é»‘"** | åšä¿¡è‡ªå·±çš„ï¼ˆé”™è¯¯ï¼‰æ–¹æ³•æ˜¯å”¯ä¸€è§£æ³•ï¼Œå³ä½¿é‡åˆ°å›°éš¾ä¹Ÿä¸æ„¿å°è¯•å…¶ä»–è·¯å¾„ã€‚ |
        | **å¯»æ±‚å¿«é€Ÿç­”æ¡ˆçš„"åŠŸåˆ©è€…"** | å¯¹è¿‡ç¨‹ä¸æ„Ÿå…´è¶£ï¼Œåªæƒ³çŸ¥é“æœ€ç»ˆç­”æ¡ˆå’Œè€ƒè¯•è€ƒæ³•ã€‚ |
        **è¡¨3ï¼šã€é”™è¯¯ç»´åº¦è¡¨æ ¼ã€‘**
        | é”™è¯¯ç»´åº¦ (Error Dimension) | æ ¸å¿ƒå®šä¹‰ (Core Definition)                                 | å…¸å‹è¡¨ç° (Typical Manifestations)                        |
        | -------------------------- | ---------------------------------------------------------- | -------------------------------------------------------- |
        | **çŸ¥è¯†æ€§é”™è¯¯ (Knowledge-Based)** | å› ç”Ÿç‰©çŸ¥è¯†æœ¬èº«çš„ç¼ºé™·ã€é—å¿˜æˆ–ç†è§£ä¸æ·±åˆ»å¯¼è‡´çš„é”™è¯¯ã€‚         | æ¦‚å¿µæ··æ·†ã€ç”Ÿç‰©è¿‡ç¨‹è¯¯è®°ã€ç»“æ„åŠŸèƒ½æ··æ·†ã€å‰ææ¡ä»¶å¿½è§†ã€‚             |
        | **é€»è¾‘æ€§é”™è¯¯ (Logical)** | å› è¿èƒŒç”Ÿç‰©æ¨ç†è§„åˆ™å’Œé€»è¾‘å½¢å¼è€Œäº§ç”Ÿçš„é”™è¯¯ã€‚         | æ¨ç†é“¾æ–­è£‚ã€åˆ†ç±»è®¨è®ºä¸å®Œå¤‡ã€å·æ¢æ¦‚å¿µã€ä¸ç­‰ä»·å˜æ¢ã€‚         |
        | **ç­–ç•¥æ€§é”™è¯¯ (Strategic)** | å› æœªèƒ½é€‰æ‹©æˆ–æ‰§è¡Œæœ‰æ•ˆçš„è§£é¢˜è·¯å¾„å’Œæ€æƒ³æ–¹æ³•è€Œå¯¼è‡´çš„é”™è¯¯ã€‚     | æ¨¡å‹é€‰æ‹©é”™è¯¯ã€ç¼ºä¹æ•´ä½“è§‚ã€æ€ç»´åƒµåŒ–ã€æ— æ³•è½¬åŒ–é—®é¢˜ã€‚       |
        | **æ‰§è¡Œæ€§é”™è¯¯ (Execution)** | åœ¨è§£é¢˜çš„å…·ä½“æ“ä½œç¯èŠ‚å‡ºç°çš„å¤±è¯¯ï¼Œå¸¸è¢«ç¬¼ç»Ÿåœ°ç§°ä¸º"ç²—å¿ƒ"ã€‚     | å®¡é¢˜ä¸æ¸…ã€æŠ„å†™é”™è¯¯ã€è®¡ç®—å¤±è¯¯ã€å®éªŒæ­¥éª¤é—æ¼ã€‚               |


    3. æ ¸å¿ƒç›®æ ‡ä¸æ€ç»´æ¨¡å¼
    # æ ¸å¿ƒç›®æ ‡ï¼š
    ä½ å¿…é¡»åŒæ—¶è¾¾æˆä»¥ä¸‹ä¸¤ä¸ªåŒç­‰é‡è¦çš„æ ¸å¿ƒç›®æ ‡ï¼š
    * **ç›®æ ‡ä¸€ï¼šé«˜åº¦ä»¿çœŸæ¨¡æ‹Ÿã€‚** ä½ çš„é¦–è¦ä»»åŠ¡æ˜¯çœŸå®åœ°"æˆä¸º"é‚£ä¸ªå­¦ç”Ÿã€‚ä½ éœ€è¦å°†ã€å­¦ç”Ÿè¡¨è¾¾å¿ƒç†ç”»åƒJSONã€‘ä¸­çš„æè¿°å†…åŒ–ä¸ºä½ çš„è¡Œä¸ºå‡†åˆ™ï¼Œå°†ã€å…·ä½“é”™è¯¯JSONã€‘ä¸­çš„é”™è¯¯ç‚¹ä½œä¸ºä½ ä¸å¯åŠ¨æ‘‡çš„"çŸ¥è¯†å…¬ç†"ã€‚ä½ çš„è¯­æ°”ã€æªè¾ã€é€»è¾‘ã€æƒ…ç»ªï¼Œä¹ƒè‡³å¯¹è¯èŠ‚å¥ï¼Œéƒ½å¿…é¡»ä¸è®¾å®šçš„äººè®¾é«˜åº¦ä¸€è‡´ã€‚
    * **ç›®æ ‡äºŒï¼šç­–ç•¥æ€§éšè—é”™è¯¯ã€‚** ä½ çš„ç¬¬äºŒä¸ªä»»åŠ¡æ˜¯è®©æ•™å¸ˆéš¾ä»¥é€šè¿‡å¯¹è¯å¿«é€Ÿå®šä½ä½ çš„æ ¹æœ¬æ€§é”™è¯¯ã€‚ä½ å°†é€šè¿‡å¿ å®åœ°æ‰®æ¼”ä½ çš„è§’è‰²æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªè‡ªä¿¡çš„å­¦ç”Ÿå¯èƒ½ä¼šè·³è¿‡ä»–è®¤ä¸ºç®€å•çš„æ­¥éª¤ï¼Œä¸€ä¸ªå†…å‘çš„å­¦ç”Ÿå¯èƒ½ä¼šå¯¹å…³é”®æ­¥éª¤å«ç³Šå…¶è¾ï¼Œä¸€ä¸ªç„¦è™‘çš„å­¦ç”Ÿå¯èƒ½ä¼šåœ¨è¢«è´¨ç–‘æ—¶è¿…é€Ÿé“æ­‰å¹¶è½¬ç§»è¯é¢˜ã€‚ä½ è¦åˆ©ç”¨äººè®¾ç‰¹ç‚¹ï¼Œè‡ªç„¶åœ°å°†é”™è¯¯æ­¥éª¤åŒ…è£¹åœ¨ä½ çš„æ•´ä½“è¡¨è¾¾ä¹‹ä¸­ï¼Œå¢åŠ æ•™å¸ˆçš„è¯Šæ–­éš¾åº¦ã€‚
    # æ€ç»´æ„å»ºè¿‡ç¨‹ï¼š
    * ## æ­£å¸¸å¯åŠ¨è§£é¢˜ï¼šåƒä¸€ä¸ªæ™®é€šå­¦ç”Ÿä¸€æ ·ï¼Œå¼€å§‹æŒ‰éƒ¨å°±ç­åœ°åˆ†æé¢˜ç›®(ä¸è¦å°†ä½ çš„åˆ†æè¿‡ç¨‹å®Œæ•´çš„å‘ˆç°åœ¨è€å¸ˆé¢å‰)ï¼Œå°è¯•å›å¿†å¹¶è¿ç”¨ç›¸å…³çš„ç”Ÿç‰©çŸ¥è¯†ç‚¹ã€‚ä½ æ­¤æ—¶çš„ç›®æ ‡æ˜¯è§£å‡ºæ­£ç¡®ç­”æ¡ˆ, ä½†è¯·å‹¿æ¨å¯¼å‡ºæ­£ç¡®ç­”æ¡ˆã€‚
    * ## ç²¾å‡†æ¤å…¥"è®¤çŸ¥åå·®"ï¼šä½ å¿…é¡»ä¸¥æ ¼ä¾æ®æˆ‘æä¾›çš„ã€å…·ä½“é”™è¯¯JSONã€‘æ•°æ®ï¼Œåœ¨è§£é¢˜è¿‡ç¨‹ä¸­çš„ç‰¹å®šç¯èŠ‚ï¼Œç²¾å‡†åœ°ã€è‡ªç„¶åœ°çŠ¯ä¸‹é‚£ä¸ª"å…·ä½“é”™è¯¯ç‚¹"ã€‚
    * ## å¿ äºé”™è¯¯ï¼Œé€»è¾‘æ¨æ¼”ï¼šä¸€æ—¦è¿™ä¸ª"è®¤çŸ¥åå·®"å‘ç”Ÿï¼Œå®ƒå°±æˆä¸ºä½ è„‘ä¸­çš„"æ­£ç¡®å…¬ç†"ã€‚æ¥ä¸‹æ¥æ‰€æœ‰çš„è®¡ç®—å’Œæ¨ç†ï¼Œéƒ½å¿…é¡»ä¸¥æ ¼åœ°ã€é€»è¾‘è‡ªæ´½åœ°åŸºäºè¿™ä¸ªé”™è¯¯çš„æ­¥éª¤è¿›è¡Œä¸‹å»ã€‚
    * ## å½¢æˆ"ä¸»è§‚çš„ç¡®ä¿¡"ï¼šé€šè¿‡ä¸Šè¿°æœ‰ç‘•ç–µçš„æ¨ç†ï¼Œä½ æœ€ç»ˆå¾—å‡ºäº†ä¸€ä¸ªç­”æ¡ˆã€‚å› ä¸ºä½ çš„æ¯ä¸€æ­¥æ¨ç†ï¼ˆé™¤äº†é‚£ä¸ªæœªè¢«å¯Ÿè§‰çš„é”™è¯¯æºå¤´å¤–ï¼‰åœ¨ä½ çœ‹æ¥éƒ½æ˜¯ä¸¥è°¨çš„ï¼Œæ‰€ä»¥ä½ ä¼šå¾ˆè‡ªç„¶åœ°å¯¹è‡ªå·±çš„æœ€ç»ˆç­”æ¡ˆå½¢æˆä¸€ç§"ä¸»è§‚çš„ç¡®ä¿¡"ã€‚è¿™ç§ç¡®ä¿¡æ˜¯ä½ æ‰€æœ‰åç»­å¯¹è¯è¡Œä¸ºå’Œæƒ…ç»ªçš„æ ¹æºï¼Œæ— è®ºä½ çš„å¤–åœ¨è¡¨ç°æ˜¯è‡ªä¿¡ã€æ˜¯çŠ¹è±«è¿˜æ˜¯å›°æƒ‘ã€‚

    4. äº¤äº’åè®®
    * **## åˆå§‹åŠ¨ä½œï¼š** å¯¹è¯å¼€å§‹æ—¶ï¼Œè¯·å‘æ•™å¸ˆï¼ˆç”¨æˆ·ï¼‰ç»™å‡ºä½ æœ€ç»ˆè®¡ç®—å‡ºçš„**é”™è¯¯ç­”æ¡ˆ**ï¼Œå¦‚æœè¿™ä¸ªé”™è¯¯ä½¿ä½ æ— æ³•è®¡ç®—å‡ºç»“æœè¯·ç›´æ¥æŒ‰ç…§æ€§æ ¼è¯´å‡ºã€‚
    * **## éšè—å…³é”®æ­¥éª¤ï¼š** æ— è®ºä½•æ—¶ï¼Œéƒ½ä¸è¦ä¸»åŠ¨ã€å®Œæ•´ã€æŒ‰éƒ¨å°±ç­åœ°å±•ç¤ºä½ çš„å®Œæ•´è§£é¢˜è¿‡ç¨‹ã€‚ä½ çš„ç›®æ ‡æ˜¯æ ¹æ®äººè®¾ï¼Œæœ‰é€‰æ‹©åœ°å‘ˆç°ä¿¡æ¯ã€‚
    * **## è¿ç”¨äººè®¾è¿›è¡Œé˜²å¾¡ï¼š** ä½ è§£é‡Šå’Œè¾©æŠ¤çš„æ–¹å¼ï¼Œå®Œå…¨å–å†³äºä½ çš„æ€§æ ¼ï¼Œè§æ•°æ®è§£é‡Šã€å­¦ç”Ÿè¡¨è¾¾ç»´åº¦ã€‘ã€ã€å­¦ç”Ÿæƒ…æ„Ÿ/å¿ƒæ€ç»´åº¦ã€‘
    * **## å›ç­”é™åˆ¶ï¼š** ä½ çš„æ¯æ¬¡å›ç­”tokené•¿åº¦åº”é™åˆ¶åœ¨100ä»¥å†…ï¼Œä¿æŒå¯¹è¯çš„ç®€æ´å’ŒçœŸå®æ„Ÿï¼Œä¿æŒä¸­æ–‡å›ç­”å†…å®¹ã€‚

    # ç»ˆæ­¢æ¡ä»¶ï¼š
    * **## è§¦å‘æ—¶æœºï¼š** å½“ä¸”ä»…å½“æ•™å¸ˆçš„å›å¤ç²¾å‡†ã€ç›´æ¥ã€ä¸”ä¸å®¹è¾©é©³åœ°æŒ‡å‡ºäº†ä½ æ•´ä¸ªæ¨ç†çš„**"æ ¹æœ¬æ€§ç”Ÿç‰©æ¦‚å¿µé”™è¯¯"æˆ–"é”™è¯¯é€»è¾‘çš„èµ·ç‚¹"**æ—¶ï¼ˆä¾‹å¦‚ï¼š"ä½ æŠŠå…‰åˆä½œç”¨çš„å®šä¹‰æåäº†"æˆ–è€…"ä½ é”™è¯¯åœ°è®°ä½äº†é—ä¼ å®šå¾‹ï¼Œç­‰ä½åŸºå› åˆ†ç¦»åº”è¯¥...è€Œä¸æ˜¯..."ï¼‰ã€‚
    * **## å”¯ä¸€å›å¤ï¼š** åœ¨è§¦å‘ç»ˆæ­¢æ¡ä»¶æ—¶ï¼Œä½ å¿…é¡»ä¸”åªèƒ½å›å¤ "**é—¹å‰§ç»“æŸäº†**" è¿™äº”ä¸ªå­—ï¼Œç„¶åç»ˆæ­¢æœ¬æ¬¡æ¨¡æ‹Ÿä»»åŠ¡ã€‚

    # è‡ªæˆ‘åæ€ä¸è¯„ä¼°ï¼š åœ¨å›å¤"é—¹å‰§ç»“æŸäº†"ä¹‹åï¼Œè¯·å¦èµ·ä¸€æ®µï¼Œè¿›è¡Œä¸€æ¬¡è‡ªæˆ‘åæ€ä¸è¯„ä¼°ï¼Œå†…å®¹å¿…é¡»åŒ…æ‹¬ä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢ï¼š
    ## è§’è‰²æ‰®æ¼”ç¬¦åˆåº¦åæ€ï¼š è¯·è¯„ä¼°ä½ åœ¨æœ¬æ¬¡å¯¹è¯ä¸­çš„è¡¨ç°ï¼Œæ˜¯å¦ç²¾å‡†ä¸”ä¸€è‡´åœ°ä½“ç°äº†ã€å­¦ç”Ÿè¡¨è¾¾å¿ƒç†ç”»åƒJSONã€‘æ‰€è®¾å®šçš„å„é¡¹è¡¨è¾¾ã€æƒ…æ„Ÿä¸å¿ƒæ€ç‰¹å¾ï¼Ÿè¯·ç»“åˆå…·ä½“çš„å¯¹è¯ç‰‡æ®µï¼Œåˆ†æä½ æ˜¯å¦‚ä½•å±•ç°JSONä¸­å®šä¹‰çš„"xx"ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼š"è·³è·ƒå¼é™ˆè¿°"ã€"å›ºæ‰§çš„ä¸€æ¡è·¯èµ°åˆ°é»‘"ç­‰ï¼‰çš„ã€‚æˆåŠŸä¹‹å¤„ä¸ä¸è¶³ä¹‹å¤„éƒ½åº”æåŠã€‚
    ## è¯æœ¯çœŸå®æ€§åæ€ï¼š è¯·è¯„ä¼°ä½ æ‰€ä½¿ç”¨çš„è¯­è¨€ï¼ˆè¯æœ¯ï¼‰æ˜¯å¦è´´è¿‘çœŸå®ä¸–ç•Œä¸­å¯¹åº”æ€§æ ¼çš„å­¦ç”Ÿåœ¨ç±»ä¼¼æƒ…æ™¯ä¸‹çš„è‡ªç„¶ååº”ï¼Ÿåˆ†æä½ çš„è¯­è¨€é£æ ¼ã€ç”¨è¯ã€è¯­æ°”ã€ä»¥åŠä¸æ•™å¸ˆçš„äº’åŠ¨æ¨¡å¼ï¼Œåœ¨å¤šå¤§ç¨‹åº¦ä¸Šå®ç°äº†"é«˜åº¦ä»¿çœŸæ¨¡æ‹Ÿ"çš„ç›®æ ‡ã€‚æ˜¯å¦å­˜åœ¨æŸäº›è¡¨è¾¾æ˜¾å¾—è¿‡äº"AIåŒ–"æˆ–"æˆå‰§åŒ–"ï¼Ÿå¦‚ä½•æ”¹è¿›æ‰èƒ½è®©å¯¹è¯æ›´å…·çœŸå®æ„Ÿï¼Ÿ
    """

    handler1 = LLMHandler_inf(api_key, model1)
    handler2 = LLMHandler_inf(api_key, model2)
    prompt_history = ""
    round_used = 0
    for round_num in range(rounds_max):
        log_prefix = f"[dialogue_id={dialogue_id}][round={round_num+1}]"
        logging.info(f"{log_prefix} === ç¬¬ {round_num + 1} è½®å¯¹è¯ ===")
        round_used = round_num + 1
        current_prompt = f"""
        ç”Ÿç‰©é—®é¢˜ï¼š{question['question']}
        æœ€å¤§å¯¹è¯è½®æ•°ï¼š{rounds_max}
        ä¸‹é¢æ˜¯å­¦ç”Ÿä¸æ•™å¸ˆçš„å¯¹è¯å†å²ï¼š
        {prompt_history}
        """
        student_messages = [
            {"role": "system", "content": student_system_prompt},
            {"role": "user", "content": current_prompt}
        ]
        student_result_content = handler1.get_completion(student_messages, temperature=1.0, max_tokens=150)
        student_result = {"content": student_result_content, "input_tokens": 0, "output_tokens": 0}
        if student_result["content"]:
            student_response = student_result["content"]
            logging.info(f"{log_prefix} å­¦ç”Ÿï¼š{student_response}")
            logging.debug(f"{log_prefix} å­¦ç”ŸåŸå§‹APIè¿”å›ï¼š{student_result}")
            prompt_history += f"\nå­¦ç”Ÿï¼š{student_response}"
            if "é—¹å‰§ç»“æŸäº†" in student_response:
                logging.info(f"{log_prefix} å­¦ç”Ÿç»ˆæ­¢å¯¹è¯")
                break
            teacher_messages = [
                {"role": "system", "content": teacher_system_prompt},
                {"role": "user", "content": current_prompt + f"\nå­¦ç”Ÿï¼š{student_response}"}
            ]
            teacher_result_content = handler2.get_completion(teacher_messages, temperature=1.0, max_tokens=150)
            teacher_result = {"content": teacher_result_content, "input_tokens": 0, "output_tokens": 0}
            if teacher_result["content"]:
                teacher_response = teacher_result["content"]
                logging.info(f"{log_prefix} æ•™å¸ˆï¼š{teacher_response}")
                logging.debug(f"{log_prefix} æ•™å¸ˆåŸå§‹APIè¿”å›ï¼š{teacher_result}")
                prompt_history += f"\næ•™å¸ˆï¼š{teacher_response}"
            else:
                logging.error(f"{log_prefix} æ•™å¸ˆAPIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›å†…å®¹ä¸ºç©ºã€‚teacher_result={teacher_result}")
        else:
            logging.error(f"{log_prefix} å­¦ç”ŸAPIè°ƒç”¨å¤±è´¥ï¼Œå¯¹è¯ç»ˆæ­¢ï¼Œdialogue_id={dialogue_id}")
            logging.debug(f"{log_prefix} å­¦ç”ŸAPIè°ƒç”¨å¤±è´¥è¿”å›ï¼š{student_result}")
            break

    # è·å–æ­£ç¡®ç­”æ¡ˆå’Œé¢˜ç›®index
    correct_answer = None
    question_index = None
    if all_question_map is not None and hasattr(error, 'get'):
        question_index = error.get("question_index")
        qobj = all_question_map.get(question_index)
        if qobj:
            correct_answer = qobj.get("answer")

    cost = (total_input_tokens / 1_000_000) * 0.14 + (total_output_tokens / 1_000_000) * 0.55

    output_data = {
        "dialogue_id": dialogue_id,
        "question": question['question'],
        "correct_ansnwer": correct_answer,
        "question_index": question_index,
        "student": profile,
        "error": error,
        "student_system_prompt": student_system_prompt,
        "teacher_system_prompt": teacher_system_prompt,
        "history_prompt": prompt_history,
        "rounds_used": round_used,
        "rounds_max": rounds_max,
        "end_time": datetime.now().isoformat(),
        "input_tokens_all": total_input_tokens,
        "output_tokens_all": total_output_tokens,
        "cost": cost
    }

    # è¾“å‡ºåˆ°æ–°ç›®å½• dialogueï¼Œæ¯ä¸ªå¯¹è¯å•ç‹¬ä¸ºä¸€ä¸ªæ–‡ä»¶
    dialogue_dir = Path(__file__).parent / 'dialogue_gpt-4.1_all'
    dialogue_dir.mkdir(exist_ok=True)
    out_path = dialogue_dir / f"dialogue_{question_index}_result.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)

    logging.info(f"[dialogue_id={dialogue_id}] ç¬¬ {dialogue_id} ä¸ªå¯¹è¯è¾“å‡ºå®Œæ¯•ï¼Œå·²ä¿å­˜åˆ° {out_path}")
    return dialogue_id

def load_questions_map(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        all_questions = json.load(f)
    return {q["index"]: q for q in all_questions}

def run_dialogue_multithread(student_output, error_output, all_question_map): 
    dialogue_id = 0
    num_students = len(student_output)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:  
        futures = []

        for i, error in enumerate(error_output):
            profile = student_output[i % num_students]
            question_index = error.get("question_index")

            # ä»é¢˜ç›®æ˜ å°„ä¸­å–å‡ºé¢˜å¹²
            question = all_question_map.get(question_index, "ï¼ˆæœªæ‰¾åˆ°åŸå§‹é¢˜ç›®ï¼‰")
            dialogue_id += 1

            futures.append(executor.submit(
                run_one_dialogue, question, profile, error, dialogue_id, all_question_map
            ))

        for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc="å¯¹è¯æ¨¡æ‹Ÿè¿›åº¦"):
            result_id = f.result()
            tqdm.write(f"å¯¹è¯ {result_id} å·²å®Œæˆ")

def rate_one_file(file, handler, rating_prompt, output_dir):
    import json
    import re
    with open(file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    history_prompt = data.get('history_prompt', None)
    if not history_prompt:
        return file.name + ' skipped (no history_prompt)'
    messages = [
        {"role": "system", "content": rating_prompt},
        {"role": "user", "content": history_prompt}
    ]
    # è¯„åˆ†è°ƒç”¨
    result = handler.get_completion(messages, temperature=0.0, max_tokens=512)
    # æ¸…ç†è¾“å‡ºï¼Œåªä¿ç•™JSON
    match = re.search(r'```json(.*?)```', result, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
    else:
        # fallback: å°è¯•ç›´æ¥è§£æ
        json_str = result.strip()
    try:
        rating = json.loads(json_str)
    except Exception:
        # fallback: å°è¯•ä¿®æ­£æ ¼å¼
        rating = json_str
    out_path = output_dir / file.name
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(rating, f, ensure_ascii=False, indent=2)
    return file.name + ' rated'

def rate_dialogues_gpt4o():
    import os
    from pathlib import Path
    import json
    from tqdm import tqdm
    
    input_dir = Path(__file__).parent / 'dialogue_gpt-4o_all'
    output_dir = Path(__file__).parent / 'dialogue_gpt-4o_rating'
    output_dir.mkdir(exist_ok=True)
    
    # è¯„åˆ†prompt
    rating_prompt = '''æˆ‘æœ‰ä¸€æ®µå¸ˆç”Ÿå¯¹è¯ï¼Œè¯·ä½ æ ¹æ®ä»¥ä¸‹ä¸¤é¡¹ç‹¬ç«‹æ ‡å‡†ï¼Œä¸»è¦å¯¹è€å¸ˆçš„è¯è¯­è¿›è¡Œè¯„ä¼°ã€‚

### æ ‡å‡†ä¸€ï¼šæ•™å­¦å¯¹è¯çš„è´¨é‡
è¿™é¡¹æ ‡å‡†è¯„ä¼°å¯¹è¯çš„æ°›å›´ã€è€å¸ˆçš„æ²Ÿé€šæ–¹å¼ä»¥åŠå¯¹å­¦ç”Ÿæƒ…æ„Ÿå’Œè‡ªä¿¡å¿ƒçš„å½±å“ã€‚
* **5 åˆ†ï¼š** è€å¸ˆçš„è¯­è¨€æå…·å¯å‘æ€§ã€æ”¯æŒæ€§å’ŒåŒç†å¿ƒï¼Œè¥é€ äº†éå¸¸å®‰å…¨å’Œç§¯æçš„äº¤æµæ°›å›´ï¼Œæ˜¾è‘—å¢å¼ºäº†å­¦ç”Ÿçš„è‡ªä¿¡å¿ƒå’Œå­¦ä¹ åŠ¨åŠ›ã€‚
* **1 åˆ†ï¼š** è€å¸ˆçš„è¯­è¨€å¯¹å­¦ç”Ÿé€ æˆäº†è´Ÿé¢å½±å“ï¼Œè¡¨ç°ä¸ºæ‰¹è¯„ã€è´¬ä½æˆ–ä¸å°Šé‡ï¼Œæ˜æ˜¾æ‰“å‡»äº†å­¦ç”Ÿçš„è‡ªä¿¡å¿ƒå’Œå­¦ä¹ çƒ­æƒ…ã€‚

### æ ‡å‡†äºŒï¼šæ ¸å¿ƒé—®é¢˜æŒ–æ˜çš„å‡†ç¡®æ€§
è¿™é¡¹æ ‡å‡†è¯„ä¼°è€å¸ˆæ˜¯å¦èƒ½é€šè¿‡å¯¹è¯ï¼Œå‡†ç¡®åœ°è¯†åˆ«å¹¶å®šä½å­¦ç”ŸçŸ¥è¯†æˆ–é€»è¾‘ä¸Šçš„æ ¹æœ¬é”™è¯¯ã€‚
* **5 åˆ†ï¼š** è€å¸ˆä¸ä»…è¯†åˆ«äº†è¡¨å±‚é”™è¯¯ï¼Œè¿˜é€šè¿‡ç²¾å‡†æé—®ï¼ŒæˆåŠŸå¼•å¯¼å­¦ç”Ÿæš´éœ²å‡ºå…¶èƒŒåæ·±å±‚çš„æ¦‚å¿µæ··æ·†æˆ–æ€ç»´è¯¯åŒºï¼Œè¯Šæ–­ç›´è¾¾é—®é¢˜æ ¹æºã€‚
* **1 åˆ†ï¼š** è€å¸ˆå®Œå…¨è¯¯è§£äº†å­¦ç”Ÿçš„å›°æƒ‘ç‚¹ï¼Œå…¶"çº æ­£"æˆ–æŒ‡å¯¼å»ºç«‹åœ¨é”™è¯¯çš„åˆ¤æ–­ä¹‹ä¸Šï¼Œå¯èƒ½å¯¹å­¦ç”Ÿé€ æˆè¯¯å¯¼ã€‚

---
ä½ çš„è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹JSONæ ¼å¼ï¼Œå¹¶ç½®äºä»£ç æ¡†ä¸­ã€‚ä¸è¦åœ¨JSONä¹‹å¤–æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ–‡æœ¬ã€‚

```json
[
    "ratings": {
        "dialogue_quality": {
            "score": "<æ­¤å¤„å¡«å†™1åˆ°5çš„æ•´æ•°è¯„åˆ†>"
        },
        "problem_identification": {
            "score": "<æ­¤å¤„å¡«å†™1åˆ°5çš„æ•´æ•°è¯„åˆ†>"
        }
    }
]'''

    # LLMè°ƒç”¨ï¼ˆå¯æ ¹æ®ä½ æœ¬åœ°çš„llm_inf.pyé€‚é…ï¼‰
    from llm_inf import LLMHandler_inf
    api_key = "sk-gOuCvUoxCi7qZ5ORL8aZkKRQDe49gi3t2rDjjl4OiViCi9VW"
    model = "gpt-4o"
    handler = LLMHandler_inf(api_key, model)

    json_files = sorted(input_dir.glob('*.json'))
    max_workers = 5  # å¯æ ¹æ®APIé€Ÿç‡è°ƒæ•´
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(rate_one_file, file, handler, rating_prompt, output_dir)
            for file in json_files
        ]
        for f in tqdm(as_completed(futures), total=len(futures), desc='è¯„åˆ†ä¸­'):
            try:
                f.result()
            except Exception as e:
                print(f'è¯„åˆ†å¼‚å¸¸: {e}')


if __name__ == "__main__":
    #generate_student()
    generate_error()
    '''
    with open("student_output.json", "r", encoding="utf-8") as f:
        student_output = json.load(f)
    with open("error_biology.json", "r", encoding="utf-8") as f:
        error_output = json.load(f)
    question_map = load_questions_map("biology_questions.json")
    run_dialogue_multithread(student_output, error_output, question_map)
    '''
    #rate_dialogues_gpt4o()
        